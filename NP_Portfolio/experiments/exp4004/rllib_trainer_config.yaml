batch_mode: truncate_episodes
callbacks:
  on_episode_end: null
  on_episode_start: null
  on_episode_step: null
  on_postprocess_traj: null
  on_sample_end: null
  on_train_result: null
clip_actions: true
clip_rewards: null
collect_metrics_timeout: 180
compress_observations: false
custom_policy_config:
  activation: relu
  cash_bias_trainable: true
  final_regularizer_weight: 1.0e-08
  predictor_filters:
  - null
  predictor_hiddens:
  - 25
  predictor_regularizer_weights:
  - 0
  predictor_type: rnn
  rebalance_cash: true
  separate_cash: true
  trading_cost: 0.002
custom_resources_per_worker: {}
dump_gradients: null
eager: false
eager_tracing: false
env: null
env_config: {}
evaluation_config: {}
evaluation_interval: null
evaluation_num_episodes: 10
gamma: 0.99
horizon: null
ignore_worker_failures: false
input: sampler
input_evaluation:
- is
- wis
learning_rate: 2.0e-05
local_tf_session_args:
  inter_op_parallelism_threads: 8
  intra_op_parallelism_threads: 8
log_level: WARN
log_sys_usage: true
lr: 0.0001
memory: 0
memory_per_worker: 0
metrics_smoothing_episodes: 100
min_iter_time_s: 0
model:
  conv_activation: relu
  conv_filters: null
  custom_action_dist: null
  custom_model: null
  custom_options: {}
  custom_preprocessor: null
  dim: 84
  fcnet_activation: tanh
  fcnet_hiddens:
  - 256
  - 256
  framestack: true
  free_log_std: false
  grayscale: false
  lstm_cell_size: 256
  lstm_use_prev_action_reward: false
  max_seq_len: 20
  no_final_linear: false
  state_shape: null
  use_lstm: false
  vf_share_layers: true
  zero_mean: true
monitor: false
multiagent:
  policies: {}
  policies_to_train: null
  policy_mapping_fn: null
no_done_at_end: false
no_eager_on_workers: false
num_cpus_for_driver: 1
num_cpus_per_worker: 1
num_envs_per_worker: 1
num_gpus: 1
num_gpus_per_worker: 0
num_workers: 0
object_store_memory: 0
object_store_memory_per_worker: 0
observation_filter: NoFilter
optimizer: {}
output: null
output_compress_columns:
- obs
- new_obs
output_max_file_size: 67108864
postprocess_inputs: false
preprocessor_pref: deepmind
remote_env_batch_wait_ms: 0
remote_worker_envs: false
replay_bias: 0.0005
sample_async: false
sample_batch_size: 200
seed: null
shuffle_buffer_size: 0
soft_horizon: false
synchronize_filters: true
tf_session_args:
  allow_soft_placement: true
  device_count:
    CPU: 1
  gpu_options:
    allow_growth: true
  inter_op_parallelism_threads: 2
  intra_op_parallelism_threads: 2
  log_device_placement: false
timesteps_per_iteration: 3000
train_batch_size: 50
